{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of training the model:\n",
    "1. Define the architecture\n",
    "2. Data processing\n",
    "3. Cinfiguring the model for the training\n",
    "4. Train the model\n",
    "\n",
    "Architecture:\n",
    " tf.keras.Sequenctial is basically \"Stacking linearly the numbers of layer If added.\"\n",
    "\n",
    "tf.keras.layers.Dense:densely-connected NN layer\n",
    "  Dense: implements the operation:\n",
    "  input:\n",
    "      Units: Dimensionality of the output space, How much units of neuron we want after the processing\n",
    "      activation: it is for learning the much complex data pattern in neural network, If no activattion funciton is being written then It automatically takes linear activation f(x) = x; but when we add softmax, relu, prelu and more, these all helps nn to learn much more complex pattern in NN;\n",
    "      use_bias: this is for whether the layer is using bias vector\n",
    "      Kernel_initilise:Initializer for the `kernel` weights matrix.\n",
    "      \n",
    "  output = activation(dot(input, kernel) + bias)`\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN archictecture: Single layer architecture takes: one neuron\n",
    "#one layer \n",
    "#Sequential used to write layer sequentially\n",
    "model  = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        input_shape=[1],\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configurng the model for training\n",
    "#Loss measures the inaccuracy between the prediction and accurate label and It send to the optimiser which guess/predicts the label for next iteration and then loss again figures how better it was before to now\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=None,\n",
    "    loss_weights=None,\n",
    "    sample_weight_mode=None,\n",
    "    weighted_metrics=None,\n",
    "    target_tensors=None,\n",
    "    distribute=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is being defined here as input(xs) and labeled/output(ys); Now model has to find the rules/pattern using this input and output data given\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype = float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype= float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints a string summary of the network.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training takes place using .fit function\n",
    "\n",
    "arguments:\n",
    "x: Input data: list of arrays, numpy arrays, list of tensorflow tensor, list of tensors, dictionalry mapping input names to corresponding array/tensors, tf.data dataset, a dataset iterator, tuples, generator\n",
    "\n",
    "y: target data: It shoudl be like the input data 'x; It should be consistent with 'input data'\n",
    "\n",
    "batch_size:No of sample per gradient update\n",
    "\n",
    "verbose: Integer (0: silent, 1: progress bar, 2: one line per epoch)\n",
    "\n",
    "callbacks: List of callbacks to apply during training; It is for handing the \n",
    "training, or manipulating the training, like when to print, when to stops, when to print the lossess, and when to save the model\n",
    "\n",
    "class_weight: Optional dictionary mapping class indices (integers)\n",
    "    to a weight (float) value, used for weighting the loss function\n",
    "    (during training only).\n",
    "    This can be useful to tell the model to\n",
    "    \"pay more attention\" to samples from\n",
    "    an under-represented class.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x=xs,\n",
    "#           y=ys,\n",
    "#           batch_size=1,\n",
    "#           epochs=500,\n",
    "#           verbose=0,\n",
    "#           callbacks=None,\n",
    "#           validation_split=0.,\n",
    "#           validation_data=None,\n",
    "#           shuffle=True,\n",
    "#           class_weight=None,\n",
    "#           sample_weight=None,\n",
    "#           initial_epoch=0,\n",
    "#           steps_per_epoch=None,\n",
    "#           validation_steps=None,\n",
    "#           max_queue_size=1,\n",
    "#           workers=1,\n",
    "#           use_multiprocessing=True)\n",
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model.predict: generates the output prediction for the input samples\n",
    "arguments:\n",
    "x: input samples, a numpy array, list of array(if the model has multiple inputs), list of the tensors, tf.data, generator\n",
    "batch_size: no of samples per gradient update\n",
    "\n",
    "'''\n",
    "    \n",
    "print(model.predict(x=[10.0],\n",
    "              batch_size=None,\n",
    "              verbose=0,\n",
    "              steps=None,\n",
    "              max_queue_size=10,\n",
    "              workers=1,\n",
    "              use_multiprocessing=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
