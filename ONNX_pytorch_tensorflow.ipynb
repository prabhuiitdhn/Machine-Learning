{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will convert the pytorch model to ONNX model then run with ONNXruntime, and check the performance between ONNX converted model and Pytorch original model. Also, we will convert the model into tensorflow.\n",
    "<!--  -->\n",
    " ONNX runtime is performance focused engine for ONNX model, can be used for inference efficiently acrsoo multiple platforms and hardware. ONNXruntime has proved to considerable increased performace over multiple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import netron\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrained_model_from_server = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super-resolution is a way of increasing the resolution of images, videos and is widely used in image processing or video editing. \n",
    "\n",
    "Super resolution model explained in “Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super Resolution model definition in PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        # Rearranges elements in a tensor of shape (*, Cxr^2, H, W) to a tensor of shape (*, C, H \\times r, W \\times r), where r is an upscale factor.\n",
    "        # This is useful for implementing efficient sub-pixel convolution with a stride of 1/r\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "        # Fills the input Tensor with a (semi) orthogonal matrix, as described in Exact solutions to the nonlinear dynamics of learning in deep linear neural networks \n",
    "\n",
    "# Create the super-resolution model by using the above model definition.\n",
    "torch_model = SuperResolutionNet(upscale_factor=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is important to call torch_model.eval() or torch_model.train(False) before exporting the model, to turn the model to inference mode. This is required since operators like dropout or batchnorm behave differently in inference and training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model weights from server or already downloaded model in local storage\n",
    "downloaded_model = 'C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/superres_epoch100-44c6958e.pth'\n",
    "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
    "batch_size = 1    # just a random number\n",
    "\n",
    "# Initialize model with the pretrained weights\n",
    "map_location = lambda storage, loc: storage\n",
    "if torch.cuda.is_available():\n",
    "    map_location = None\n",
    "    if load_pretrained_model_from_server is True:\n",
    "        # load the model's parameter dictionary using the deserialised state_dict\n",
    "        '''\n",
    "        A state_dict is simply a Python dictionary object that maps each layer to its parameter tensor. \n",
    "        Note that only layers with learnable parameters (convolutional layers, linear layers, etc.) and \n",
    "        registered buffers (batchnorm’s running_mean) have entries in the model’s state_dict. \n",
    "        Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizer’s state, \n",
    "        as well as the hyperparameters used.\n",
    "        \n",
    "        Because state_dict objects are Python dictionaries, they can be easily saved, updated, altered, and restored, \n",
    "        adding a great deal of modularity to PyTorch models and optimizers.\n",
    "        '''\n",
    "        torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location))\n",
    "    else:\n",
    "        torch_model.load_state_dict(torch.load(downloaded_model))\n",
    "\n",
    "# set the model to inference mode\n",
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input to the model\n",
    "x = torch.randn(batch_size, 1, 224, 224, requires_grad=True)\n",
    "torch_out = torch_model(x)\n",
    "print(torch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the torch model to ONNX format of pytorchModel\n",
    "'''\n",
    " Exporting a model in PyTorch works via tracing or scripting. This tutorial will use as an example a model exported by tracing. \n",
    " To export a model, we call the torch.onnx.export() function. This will execute the model, \n",
    " recording a trace of what operators are used to compute the outputs. Because export runs the model, \n",
    " we need to provide an input tensor x.\n",
    "\n",
    "'''\n",
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        # Rearranges elements in a tensor of shape (*, Cxr^2, H, W) to a tensor of shape (*, C, H \\times r, W \\times r), where r is an upscale factor.\n",
    "        # This is useful for implementing efficient sub-pixel convolution with a stride of 1/r\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "        # Fills the input Tensor with a (semi) orthogonal matrix, as described in Exact solutions to the nonlinear dynamics of learning in deep linear neural networks \n",
    "\n",
    "# Create the super-resolution model by using the above model definition.\n",
    "torch_model_ = SuperResolutionNet(upscale_factor=3)\n",
    "# torch.load with map_location=torch.device('cpu')\n",
    "if torch.cuda.is_available() is False:\n",
    "    torch_model = torch_model.load_state_dict(torch.load(downloaded_model, map_location = lambda storage, loc: storage))\n",
    "else:\n",
    "    torch_model_ = torch_model_.load_state_dict(torch.load(downloaded_model))\n",
    "dummy_input = Variable(torch.randn(1, 1, 224, 224))\n",
    "# torch.onnx.export(torch_model,               # model being run\n",
    "#                   x,                         # model input (or a tuple for multiple inputs)\n",
    "#                   \"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "#                   export_params=True,        # store the trained parameter weights inside the model file\n",
    "#                   opset_version=10,          # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "#                   input_names = ['input'],   # the model's input names\n",
    "#                   output_names = ['output'], # the model's output names\n",
    "#                   dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
    "#                                 'output' : {0 : 'batch_size'}})\n",
    "torch.onnx.export(torch_model_,dummy_input,\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before verifying the model’s output with ONNX Runtime, we will check the ONNX model with ONNX’s API. First, onnx.load(\"super_resolution.onnx\") will load the saved model and will output a onnx.ModelProto structure (a top-level file/container format for bundling a ML model\n",
    "Then, onnx.checker.check_model(onnx_model) will verify the model’s structure and confirm that the model has a valid schema. The validity of the ONNX graph is verified by checking the model’s version, the graph’s structure, as well as the nodes and their inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "# loading the onnx model\n",
    "onnx_model = onnx.load(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.onnx\")\n",
    "# onnx.checker.check_model(onnx_model) will verify the model’s structure and confirm that the model has a valid schema. The validity of the ONNX graph is verified by checking the model’s version, the graph’s structure, as well as the nodes and their inputs and outputs.\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the output using ONNX run time's python API, we need to start the session using InferenceSession() and .run() the session.\n",
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.onnx\")\n",
    "\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/cat_224x224.jpg\")\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "\n",
    "#  we split the image into its Y, Cb, and Cr components. These components represent a greyscale image (Y), and the blue-difference (Cb) and red-difference (Cr) chroma components.\n",
    "\n",
    "img_ycbcr = img.convert('YCbCr')\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "#  split the image into its Y(greyscale image), Cb(blue difference), and Cr(red-difference) components\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_y = to_tensor(img_y)\n",
    "img_y.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Started then session, get the inputs, run the session for predicted.\n",
    "# take the tensor representing the greyscale resized cat image and run the super-resolution model in ONNX Runtime as explained previously.\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "img_out_y = ort_outs[0]\n",
    "print(\"Output as tensor:\\n\", img_out_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
    "\n",
    "# get the output image follow post-processing step from PyTorch implementation\n",
    "final_img = Image.merge(\"YCbCr\", (img_out_y, img_cb.resize(img_out_y.size, Image.BICUBIC), img_cr.resize(img_out_y.size, Image.BICUBIC))).convert('RGB')\n",
    "\n",
    "final_img.save(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/inference_cat_superres_with_ort.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/inference_cat_superres_with_ort.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COnvert the ONNX model to tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the model graph using netron\n",
    "import netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watching the original pytorch model in netron\n",
    "netron.start(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/superres_epoch100-44c6958e.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watching the ONNX converted model in netron\n",
    "netron.start(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converted the onnx model to tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from onnx_tf.backend import prepare\n",
    "onnx_model  = onnx.load(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.onnx\")\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watching converted tensorflow model in netron\n",
    "netron.start(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.pb/saved_model.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing Log directory; Generating event files for tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "from tensorflow.core.protobuf import saved_model_pb2\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "\n",
    "    model_filename = 'C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.pb/saved_model.pb'\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "        data = compat.as_bytes(f.read())\n",
    "        sm = saved_model_pb2.SavedModel()\n",
    "        sm.ParseFromString(data)\n",
    "        # print(sm)\n",
    "        if 1 != len(sm.meta_graphs):\n",
    "            print('More than one graph found. Not sure which to write')\n",
    "            sys.exit(1)\n",
    "\n",
    "        # graph_def = tf.GraphDef()\n",
    "        # graph_def.ParseFromString(sm.meta_graphs[0])\n",
    "        g_in = tf.import_graph_def(sm.meta_graphs[0].graph_def)\n",
    "LOGDIR = 'C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution_events/'\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "train_writer = tf.compat.v1.summary.FileWriter(LOGDIR)\n",
    "# train_writer = tf.summary.create_file_writer(LOGDIR)\n",
    "train_writer.add_graph(sess.graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/tools/import_pb_to_tensorboard.py\n",
    "\n",
    "Trying to open tensorboard and plotting .pb file as graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports a protobuf model as a graph in Tensorboard.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.client import session\n",
    "from tensorflow.python.framework import importer\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.summary import summary\n",
    "\n",
    "\n",
    "def import_to_tensorboard(model_dir, log_dir):\n",
    "    \"\"\"View an imported protobuf model (`.pb` file) as a graph in Tensorboard.\n",
    "    Args:\n",
    "      model_dir: The location of the protobuf (`pb`) model to visualize\n",
    "      log_dir: The location for the Tensorboard log to begin visualization from.\n",
    "    Usage:\n",
    "      Call this function with your model location and desired log directory.\n",
    "      Launch Tensorboard by pointing it to the log directory.\n",
    "      View your imported `.pb` model as a graph.\n",
    "    \"\"\"\n",
    "    with session.Session(graph=ops.Graph()) as sess:\n",
    "        print(\"I am here..\")\n",
    "        with gfile.FastGFile(model_dir, \"rb\") as f:\n",
    "            print(\"Yes\")\n",
    "            graph_def = graph_pb2.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            importer.import_graph_def(graph_def)\n",
    "        print(\"yes\")\n",
    "        pb_visual_writer = summary.FileWriter(log_dir)\n",
    "        pb_visual_writer.add_graph(sess.graph)\n",
    "        print(\"Model Imported. Visualize by running: \"\n",
    "              \"tensorboard --logdir={}\".format(log_dir))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   parser = argparse.ArgumentParser()\n",
    "#   parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "#   parser.add_argument(\n",
    "#       \"--model_dir\",\n",
    "#       type=str,\n",
    "#       default=\"\",\n",
    "#       required=True,\n",
    "#       help=\"The location of the protobuf (\\'pb\\') model to visualize.\")\n",
    "#   parser.add_argument(\n",
    "#       \"--log_dir\",\n",
    "#       type=str,\n",
    "#       default=\"\",\n",
    "#       required=True,\n",
    "#       help=\"The location for the Tensorboard log to begin visualization from.\")\n",
    "#   FLAGS, unparsed = parser.parse_known_args()\n",
    "#   app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir = \"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.pb/saved_model.pb\"\n",
    "# log_dir = \"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution_events/\"\n",
    "# import_to_tensorboard(model_dir, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference using .pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import logging, os\n",
    "logging.disable(logging.warning)\n",
    "\n",
    "# INPUT_TENSOR_NAME = 'input.1:0'\n",
    "INPUT_TENSOR_NAME = 'serving_default_input.1'\n",
    "OUTPUT_TENSOR_NAME = 'output:0'\n",
    "image_path = 'C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/cat_224x224.jpg'\n",
    "pb_path = \"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/super_resolution.pb/saved_model.pb\"\n",
    "\n",
    "img = Image.open(\"C:/Users/uib43225/PycharmProjects/DSAlgo/onnx/cat_224x224.jpg\")\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "\n",
    "# image = cv2.imread(image)\n",
    "# image = np.dot(image[...,:3], [0.299, 0.587, 0.114])\n",
    "# image = cv2.resize(image, dsize=(28, 28), interpolation = cv2.INTER_AREA)\n",
    "# image.resize((1, 1, 28, 28))\n",
    "\n",
    "with tf.gfile.FastGFile(pb_path, 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    \n",
    "with tf.Graph().as_default() as graph:\n",
    "    tf.import_graph_def(graph_def, name= \"\")\n",
    "    \n",
    "input_tensor = graph.get_tensor_by_name(INPUT_TENSOR_NAME)\n",
    "output_tensor = graph.get_tensor_by_name(OUTPUT_TENSOR_NAME)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    output_vals = sess.run(output_tensor, feed_dict ={input_tensor:img})\n",
    "    \n",
    "print(output_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
